{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ef6532-9295-4eb7-9bcc-a41b101dde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2c1b2b-6f16-40c9-a502-e43e22aa2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package comtrans to\n",
      "[nltk_data]     C:\\Users\\Garrett\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package comtrans is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('comtrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f85312-ce8e-4781-a4f5-be3beccbbbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AlignedSent: 'Please rise , then ,...' -> 'Je vous invite à vou...'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import comtrans\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57354f4-420d-4fea-b26c-6b62560c86e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comtrans.aligned_sents('alignment-en-fr.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b374f59-c877-442f-8b66-7290a5d75e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Please', 'rise', ',', 'then', ',', 'for', 'this', 'minute', \"'\", 's', 'silence', '.']\n"
     ]
    }
   ],
   "source": [
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[3].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a042967b-849a-420d-bfaa-1e1715716ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Je', 'vous', 'invite', 'à', 'vous', 'lever', 'pour', 'cette', 'minute', 'de', 'silence', '.']\n"
     ]
    }
   ],
   "source": [
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[3].mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727ba69d-272f-4541-9689-dc777767aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0 0-1 0-2 0-4 1-5 5-6 6-7 7-8 8-10 9-9 9-10 10-10 11-11\n"
     ]
    }
   ],
   "source": [
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[3].alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81f19d0-c048-43e3-a312-08187c4b6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a795509d-7e9d-4bc3-bac8-c93b58255e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sent = [sent.words for sent in comtrans.aligned_sents('alignment-en-fr.txt')]\n",
    "french_sent = [sent.mots for sent in comtrans.aligned_sents('alignment-en-fr.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93b44a6-d991-4e9c-a3ff-8e3efdc8ffdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Resumption', 'of', 'the', 'session']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "051b9df3-3453-4643-be71-cca62c693442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reprise', 'de', 'la', 'session']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6343b3a-463b-42cb-92a6-6972c1e3da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff33d07-759d-46c6-bcc4-0ea108527ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c6ff20-3f5e-45e5-b6d9-eb2c98de00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence2 = [s.translate(str.maketrans('','',string.punctuation)) for s in sentence]\n",
    "    clean_words = [word.lower() for word in sentence2 if word != '']\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d55dc18-85b4-41b1-8c28-8e5fc3301c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sen_en = [clean_sentence(s) for s in english_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4136e39-4f86-48ab-b3d0-5a486b9ed848",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sen_fr = [clean_sentence(s) for s in french_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26d659ca-de60-49e1-8915-14a6a38189f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentence_length(sentences_l1, sentences_l2, min_len=0, max_len=20):\n",
    "    filtered_sentences_l1=[]\n",
    "    filtered_sentences_l2=[]\n",
    "    for i in range(len(sentences_l1)):\n",
    "        if min_len <= len(sentences_l1[i]) <= max_len and min_len <= len(sentences_l2[i]) <= max_len:\n",
    "            filtered_sentences_l1.append(sentences_l1[i])\n",
    "            filtered_sentences_l2.append(sentences_l2[i])\n",
    "    return filtered_sentences_l1, filtered_sentences_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbab2b73-5742-4916-9cbe-cd41af1548dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_clean_sen_en, filt_clean_sen_fr = filter_sentence_length(clean_sen_en, clean_sen_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0510020-7715-4b44-bb96-2936ee2acb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexed_dictionary(sentences, dict_size=10000, storage_path=None):\n",
    "    count_words = Counter()\n",
    "    dict_words = {}\n",
    "    for sen in sentences:\n",
    "        for word in sen:\n",
    "            count_words[word] += 1\n",
    "    \n",
    "    for idx, item in enumerate(count_words.most_common(dict_size)):\n",
    "        dict_words[item[0]] = idx +1\n",
    "        \n",
    "    if storage_path:\n",
    "        pickle.dump(dict_words, open(storage_path, 'wb'))\n",
    "    return dict_words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad3bee1c-6b97-4db2-9f06-593ab54cf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indexes(sentences, indexed_dictionary):\n",
    "    indexed_sentences = []\n",
    "    not_found_counter = 0\n",
    "    for sent in sentences:\n",
    "        idx_sent = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                idx_sent.append(indexed_dictionary[word])\n",
    "            except KeyError:\n",
    "                idx_sent.append(data_utils.UNK_ID)\n",
    "                not_found_counter += 1\n",
    "        indexed_sentences.append(idx_sent)\n",
    "\n",
    "    print('[sentences_to_indexes] Did not find {} words'.format(not_found_counter))\n",
    "    return indexed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcbe7fa6-b57f-46cc-874f-60ecaf67d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_en = create_indexed_dictionary(filt_clean_sen_en, dict_size=15000, storage_path='en_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93a937b-4225-4748-a9f1-9b1f28a40caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_fr = create_indexed_dictionary(filt_clean_sen_fr, dict_size=15000, storage_path='fr_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "329f3d73-0ff7-4872-9ddb-a68c9cff4ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sentences_to_indexes] Did not find 0 words\n"
     ]
    }
   ],
   "source": [
    "idx_sentences_en = sentences_to_indexes(filt_clean_sen_en, dict_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c4a5cfb-67c6-4e9a-9a0a-3f6b07365427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sentences_to_indexes] Did not find 0 words\n"
     ]
    }
   ],
   "source": [
    "idx_sentences_fr = sentences_to_indexes(filt_clean_sen_fr, dict_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f05acad-565f-4559-809c-23c2715c79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_max_length(corpora):\n",
    "    return max([len(sentence) for sentence in corpora])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60d55864-5666-4f72-8dad-92cebfe05cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_en = extract_max_length(idx_sentences_en)\n",
    "max_length_fr = extract_max_length(idx_sentences_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44745ce0-9094-44e7-b7a5-cde39325df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentences(sentences_en, sentences_fr, len_en, len_fr):\n",
    "    assert len(sentences_en) == len(sentences_fr)\n",
    "    data_set = []\n",
    "    for i in range(len(sentences_en)):\n",
    "        padding_en = len_en - len(sentences_en[i])\n",
    "        pad_sentence_en = sentences_en[i] + ([0] * padding_en)\n",
    "        padding_fr = len_fr - len(sentences_fr[i])\n",
    "        pad_sentence_fr = sentences_fr[i] + ([0] * padding_fr)\n",
    "        data_set.append([pad_sentence_en, pad_sentence_fr])\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e31733b7-df95-44ae-8379-dd25f88a602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = prepare_sentences(idx_sentences_en, idx_sentences_fr, max_length_en, max_length_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc421270-7030-4bf6-8165-531f05768c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = array(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdbf183b-ceb7-4bc0-8537-b4ac6a3c8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "608d3e96-afa2-444b-9421-3ae883687288",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_encoded = []\n",
    "fr_encoded = []\n",
    "for i in range(len(data_set)):\n",
    "    en_encoded.append(data_set[i][0])\n",
    "    fr_encoded.append(data_set[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "999f03d8-745b-47ff-b2c0-e4a375f91f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_encoded = array(en_encoded)\n",
    "fr_encoded = array(fr_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5323ae6e-c4d8-492b-ab1d-b923b41a6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train, en_test, fr_train, fr_test = train_test_split(en_encoded, fr_encoded, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "693ad376-2ca5-4f3b-93ad-8787c426ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(dict_fr), 256, input_length = len(fr_train[0]), mask_zero=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(RepeatVector(len(en_train[0])))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dense(len(dict_en), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5fcda15-2dc4-4162-9d3d-9318bd7fca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb92bb32-94d8-4dad-b28f-39150bf14886",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1aac2117-e8e7-4c23-aa87-1de6651e5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.h1.16_sep_21'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=False, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13562587-0fb1-48e4-b32a-fb07e5e4c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(fr_train, en_train.reshape(en_train.shape[0], en_train.shape[1], 1),\n",
    "                   epochs=30, batch_size=256, validation_split = 0.2, callbacks=[checkpoint],\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaadac98-d16d-41df-bd5f-01c52dcf26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h1.16_sep_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8e4c712-08f7-42da-870c-4c4807c210cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4209,20,10670] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16468/4010667421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfr_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1766\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m     \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;31m# If originally PSS strategy was used, then replace it back since predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m   \"\"\"\n\u001b[1;32m-> 1376\u001b[1;33m   return map_structure_with_tuple_paths_up_to(\n\u001b[0m\u001b[0;32m   1377\u001b[0m       \u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m       \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Discards the path arg.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1472\u001b[0m   flat_path_gen = (\n\u001b[0;32m   1473\u001b[0m       path for path, _ in _yield_flat_up_to(shallow_tree, inputs[0], is_seq))\n\u001b[1;32m-> 1474\u001b[1;33m   results = [\n\u001b[0m\u001b[0;32m   1475\u001b[0m       \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_path_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mflat_value_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m   ]\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1473\u001b[0m       path for path, _ in _yield_flat_up_to(shallow_tree, inputs[0], is_seq))\n\u001b[0;32m   1474\u001b[0m   results = [\n\u001b[1;32m-> 1475\u001b[1;33m       \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_path_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mflat_value_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1476\u001b[0m   ]\n\u001b[0;32m   1477\u001b[0m   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(_, *values)\u001b[0m\n\u001b[0;32m   1376\u001b[0m   return map_structure_with_tuple_paths_up_to(\n\u001b[0;32m   1377\u001b[0m       \u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m       \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Discards the path arg.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m       \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m       **kwargs)\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(tensors, axis)\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1768\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1769\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1210\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4209,20,10670] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "preds = argmax(model.predict(fr_test.reshape((fr_test.shape[0],fr_test.shape[1]))), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a633e7e-6d1c-4101-bc8c-ecaf3c65b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, dictionary):\n",
    "    for word, value in dictionary.items():\n",
    "    if value == n:\n",
    "        return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12feaff8-ce0d-4eb5-bc36-f950ebe86f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], dict_en)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], dict_en)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "        else:\n",
    "            temp.append(t)\n",
    "    preds_text.append(' '. join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe68ba-137b-40cc-b486-ddb507d43a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
