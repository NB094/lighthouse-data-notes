{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling with Python: Intro to Pandas\n",
    "Note: Notebook adapted from [here](https://github.com/EricElmoznino/lighthouse_pandas_tutorial/blob/master/pandas_tutorial.ipynb) & [here](https://github.com/sedv8808/LighthouseLabs/tree/main/W02D2) & from LHL's [21 Day Data Challenge](https://data-challenge.lighthouselabs.ca/start)\n",
    "#### Instructor: Andrew Berry\n",
    "#### Date: July 27, 2021\n",
    "\n",
    "**Agenda:**\n",
    " - Why Pandas?\n",
    " - Pandas Basics\n",
    "     - Pandas Series vs. Pandas DataFrames\n",
    "     - .loc() vs. iloc()\n",
    " - Pandas Advance\n",
    "     - Filtering\n",
    "     - Group bys\n",
    " - Pandas Exercises\n",
    "     - Challenge 1\n",
    "     - Challenge 2\n",
    "\n",
    "### Pandas: Why Pandas? What is it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do data anlaysis with Python, Pandas is a great tool to for dealing with data in a tabular and time series formats. Designed by Wes McKinney as an attempt to port R's dataframes to python. \n",
    "\n",
    "- Python Package for working with **tables**\n",
    "- Similar to SQL & Excel\n",
    "    - Faster\n",
    "    - More features to manipulate, transform, and aggregate data\n",
    "- Easy to handle messy and missing data\n",
    "- Great at working with large data files\n",
    "- When combing with other Python libraries, it's fairly easy to create bautiful and customazied visuals. Easy integration with Matplotlib, Seaborn, Plotly.\n",
    "- Easy integration with machine learning plugins (sckit-learn)\n",
    "    \n",
    "    \n",
    "-----------\n",
    "To read more about, Wes McKinney, the creator of Pandas, check out the article below.\n",
    "\n",
    "1. https://qz.com/1126615/the-story-of-the-most-important-tool-in-data-science/\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think of how we would try to represent a table in Python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dicitonary of lists example\n",
    "students = {\n",
    "    'student_id': [1, 2, 3, 4,5,6],\n",
    "    'name': ['Daenerys', 'Jon', 'Arya', 'Sansa', 'Eddard', 'Khal Drogo'],\n",
    "    'course_mark': [82, 100, 12, 76, 46, 20],\n",
    "    'species': ['cat', 'human', 'cat', 'human', 'human', 'human']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are some operations we might want to do on this data?**\n",
    "\n",
    "- 1.Select a subset of columns\n",
    "- 2.Filter out some rows based on an attribute\n",
    "- 3.Group by some attribute\n",
    "- 4.Compute some aggregate values within groups\n",
    "- 5.Save to a file\n",
    "\n",
    "How about we try out one of these to see how easy it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to return a table with the mean course mark per-species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 47.0, 'human': 60.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a table with the mean course mark per-species\n",
    "# Think about a SQL statment where we group by species with the average course mark\n",
    "\n",
    "species_sums = {} #Tables of Sums\n",
    "species_counts = {} #Count per Species\n",
    "for i in range(len(students['species'])):  #iterating over the rows\n",
    "    species = students['species'][i] #every row number I get species \n",
    "    course_mark = students['course_mark'][i] #  and course mark\n",
    "    if species not in species_sums: #Intializing Species if not in list\n",
    "        species_sums[species] = 0\n",
    "        species_counts[species] = 0\n",
    "    species_sums[species] += course_mark #Add each course mark for each species\n",
    "    species_counts[species] += 1 \n",
    "\n",
    "species_means = {}\n",
    "                                  \n",
    "for species in species_sums: # for every unique species we found\n",
    "    species_means[species] = species_sums[species] / species_counts[species] #sum/count\n",
    "\n",
    "species_means #return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Did you like looking at is? Does this look fun to do?\n",
    "- Super Tiring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Version\n",
    "import pandas as pd\n",
    "\n",
    "# Can take in a dictionry of list to instatiate a DataFrame\n",
    "students = pd.DataFrame(students) \n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_means = students[['species', 'course_mark']].groupby('species').mean()\n",
    "#species_means = students.groupby('species')['course_mark'].mean()\n",
    "species_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissecting the above code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Filter out the columns we want to keep\n",
    "students_filtered = students[['species','course_mark']]\n",
    "students_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by species column\n",
    "students_grouped_by_species = students_filtered.groupby('species') \n",
    "students_grouped_by_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Specify how to aggregate the course-mark column\n",
    "species_means = students_grouped_by_species.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As shown, Pandas makes use of vectorized operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Rather than use for-loops, we specify the operation that will apply to the structure as a whole (i.e. all the rows)\n",
    "- By vectorizing, **the code becomes more concise and more readable**\n",
    "- Pandas is optimized for vectorized operations (parallel vs. serial computation), which makes them **much faster**\n",
    "- It is almost always possible to vectorize operations on Pandas data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started: Pandas Series & Pandas DataFrames\n",
    "\n",
    "There are two Pandas data types of interest:\n",
    "\n",
    "- Series (column)\n",
    "    - A pandas series is similar to an array but it has an index. The index is constant, and doesnt change through the operations we apply to the series. \n",
    "- DataFrame (table)\n",
    "    - A pandas dataframe is an object that is similar to a collection of pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to construct a Series\n",
    "series = pd.Series([82, 100, 12, 76, 46, 20]) \n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can specify some index when building a series. \n",
    "grades = pd.Series([82, 100, 12, 76, 46, 20], \n",
    "                   index = ['Daenerys', 'Jon', 'Arya', 'Sansa', 'Eddard', 'Khal Drogo'] ) \n",
    "\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The values:\", grades.values)\n",
    "print(\"The indexes:\", grades.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The underlying index is still 0, 1, 2, 3.... and we can still index on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to construct a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Daenerys', 'Jon', 'Arya', 'Sansa'],\n",
    "    'course_mark': [82, 100, 12, 76],\n",
    "    'species': ['human', 'human', 'cat', 'human']},\n",
    "    index=[1412, 94, 9351, 14])\n",
    "    # Underlying index is still 1, 2 , 3\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV file\n",
    "\n",
    "We'll use the function `read_csv()` to load the data into our notebook\n",
    "\n",
    "- The `read_csv()` function can read data from a locally saved file or from a URL\n",
    "- We'll store the data as a variable `df_pokemon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon = pd.read_csv('pokemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do we see here?**\n",
    "- Each row of the table is an observation, containing data of a single pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large DataFrames, it's often useful to display just the first few or last few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pro tip:**\n",
    "> - To display the documentation for this method within Jupyter notebook, you can run the command `df_pokemon.head?` or press `Shift-Tab` within the parentheses of `df_pokemon.head()`\n",
    "> - To see other methods available for the DataFrame, type `df_pokemon.` followed by `Tab` for auto-complete options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon.head?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data at a Glance\n",
    "\n",
    "`pandas` provides many ways to quickly and easily summarize your data:\n",
    "- How many rows and columns are there?\n",
    "- What are all the column names and what type of data is in each column?\n",
    "- How many values are missing in each column or row?\n",
    "- Numerical data: What is the average and range of the values?\n",
    "- Text data: What are the unique values and how often does each occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peeking into the pokemon dataset\n",
    "\n",
    "- Similar with getting familar with SQL tables, it is often a great idea to look at the pandas dataframes we are working with. Below are some of the basic methods to glance at a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Columns\n",
    "df_pokemon.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Summary Statistics\n",
    "df_pokemon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon[['Total', 'Attack']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon['Attack'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_attack = df_pokemon['Attack'].std()\n",
    "std_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon.HP.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon['Sp. Atk'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for Missing Data\n",
    "df_pokemon.isnull().sum() / len(df_pokemon) * 100   # Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The .loc() vs .iloc() method\n",
    "\n",
    "\n",
    "To select rows and columns at the same time, we use the syntax `.loc[<rows>, <columns>]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice the square brackets on loc and the colon\n",
    "df_pokemon.loc[10:20, ['Name']]\n",
    "# Notice that row 20 is not excluded with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a slice of index values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting more than one columns\n",
    "df_pokemon.loc[10:20, ['Name', 'Legendary', 'Attack']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also feed in a list for the rows\n",
    "df_pokemon.loc[[10, 14, 24, 321, 732], ['Name', 'Legendary', 'Attack']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also slice over  range of column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iloc is use for integer based indexing\n",
    "df_pokemon.iloc[0:3,1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying a Column or Creating a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pokemon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a hard copy of the dataset so work can safely be done without \n",
    "# modifying the original.\n",
    "\n",
    "df2 = df_pokemon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Attack'] = df2['Attack'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a filler column\n",
    "df2['filler'] = True\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Total_Defense'] = df2['Defense'] + df2['Sp. Def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy total and creat that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify an orginal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify Data Frame with .loc() method\n",
    "df2.loc[1,['Name']] = 'Andrew'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort_values() & value_counts()\n",
    "\n",
    "1. ***df.sort_values()***\n",
    "2. ***df.value_counts()***\n",
    "\n",
    "\n",
    "The ***pandas.sort_values()*** allows us to reorder our dataframe in an ascending or descending order given a column for pandas to work from. This is similar to the excel sort function.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('random.csv')\n",
    "df\n",
    "\n",
    "\n",
    "df.sort_values(by=['some_column'], ascending = True)\n",
    "```\n",
    "In the above code snippet, we are sorting our *random.csv* pandas data frame by the column *some_column* in ascending order. To read more on the ***df.sort_values()*** function, read this [article](https://datatofish.com/sort-pandas-dataframe/).\n",
    "\n",
    "The second function is ***df.value_counts()***, it allows us to count how many times a specific value/item occurred in the dataframe. This function is best used on a specific column on a data frame, ideally on a column representing categorical data. Categorical data refers to a statistical data type consisting of categorical variables. \n",
    "\n",
    "```python\n",
    "df['column'].value_counts()\n",
    "```\n",
    "\n",
    "To read more on some of the advanced functionalities of ***df.value_counts()***, please refer to the pandas documentation or this [article](https://towardsdatascience.com/getting-more-value-from-the-pandas-value-counts-aa17230907a6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by=['Generation'],ascending=False)\n",
    "# Save this into another variable if you want to save the dataset that way\n",
    "another_variable = df2.sort_values(by=['Generation'],ascending=False)\n",
    "another_variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also sort by multiple values\n",
    "df2.sort_values(by=['Attack', 'Defense'],ascending=[True, False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts\n",
    "\n",
    "df2['Type 1'].value_counts(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Type 1'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Unique Values\n",
    "df2['Type 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many unique Values\n",
    "df2['Type 1'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Query or Filter Data with Conditions?\n",
    "\n",
    "- We can extract specific data from our dataframe based on a specific condition. We will be using the syntax below. Pandas will return a subset of the dataframe based on the given condition. \n",
    "\n",
    "```python\n",
    "df[<insert_condition>]\n",
    "```\n",
    "\n",
    "Conditions follow the generic boolean logic in Python. Below is a cheat sheet python boolean logic.\n",
    "\n",
    "**Conditional Logic:** \n",
    "\n",
    "Conditional logic refers to the execution of different actions based on whether a certain condition is met. In programming, these conditions are expressed by a set of symbols called **Boolean Operators**. \n",
    "\n",
    "| Boolean Comparator | Example | Meaning                         |\n",
    "|--------------------|---------|---------------------------------|\n",
    "| >                  | x > y   | x is greater than y             |\n",
    "| >=                 | x >= y  | x is greater than or equal to y |\n",
    "| <                  | x < y   | x is less than y                |\n",
    "| <=                 | x <= y  | x is less than or equal to y    |\n",
    "| !=                 | x != y  | x is not equal to y             |\n",
    "| ==                 | x == y  | x is equal to y                 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create a filter\n",
    "#the_filter = df2['Total'] > 300\n",
    "the_filter = (df2['Total'] > 300) & (df2['Legendary'] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Apply Filter\n",
    "df2[the_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Only Legendary Pokemons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregation \n",
    "\n",
    "Grouping and aggregation can be used to calculate statistics on groups in the data.\n",
    "\n",
    "**Common Aggregation Functions**\n",
    "- mean()\n",
    "- median()\n",
    "- sum()\n",
    "- count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pokemon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attack','Defense','Type 1']].groupby('Type 1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, `groupby()` assigns the variable that we're grouping on (in this case `Type 1`) to the index of the output data\n",
    "- If we use the keyword argument `as_index=False`, the grouping variable is instead assigned to a regular column\n",
    "  - This can be useful in some situations, such as data visualization functions which expect the relevant variables to be in columns rather than the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df[['Attack','Defense','Type 1']].groupby('Type 1').mean().reset_index()\n",
    "# or\n",
    "# df[['Attack','Defense','Type 1']].groupby('Type 1', as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attack','Defense','Type 1','Legendary']].groupby(['Type 1', 'Legendary']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `agg` method to compute multiple aggregated statistics on our data, for example minimum and maximum country populations in each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attack','Type 1']].groupby('Type 1').agg(['min','max','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `agg` to compute different statistics for different columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict =  {\n",
    "    \n",
    "    'Attack': 'mean',\n",
    "    'Defense': ['min','max']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attack','Defense','Type 1']].groupby('Type 1').agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (20 minutes)\n",
    "\n",
    "Let's play around with Pandas on a more intricate dataset: a dataset on wines!\n",
    "\n",
    "**Challenge 14 from the 21 Day Data Challenge** \n",
    "\n",
    "Dot's neighbour said that he only likes wine from Stellenbosch, Bordeaux, and the Okanagan Valley, and that the sulfates can't be that high. The problem is, Dot can't really afford to spend tons of money on the wine. Dot's conditions for searching for wine are: \n",
    "1. Sulfates cannot be higher than 0.6. \n",
    "2. The price has to be less than  $20. \n",
    "\n",
    "Use the above conditions to filter the data for questions **2 and 3** below. \n",
    "\n",
    "**Questions:**\n",
    "1. Where is Stellenbosch, anyway? How many wines from Stellenbosch are there in the *entire dataset*? \n",
    "2. *After filtering with the 2 conditions*, what is the average price of wine from the Bordeaux region? \n",
    "3. *After filtering with the 2 conditions*, what is the least expensive wine that's of the highest quality from the Okanagan Valley?\n",
    "\n",
    "\n",
    "\n",
    "**Stretch Question:**\n",
    "1. What is the average price of wine from Stellenbosch, according to the entire unfiltered dataset? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('winequality-red_2.csv')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "# Sulfates cannot be higher than 0.6.\n",
    "# The price has to be less than $20.\n",
    "\n",
    "wine_filter = (df['sulphates'] <= 0.6) & (df['price'] < 20)\n",
    "df_filtered = df[wine_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_filter = df['region'] == 'Stellenbosch'\n",
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby('region')['price'].mean()\n",
    "# Q2 answer: 11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_region = df['region'] == 'Okanagan Valley'\n",
    "df_filtered = df_filtered[filter_region]\n",
    "df_filtered.sort_values(by=['price','quality'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (25 minutes)\n",
    "\n",
    "**Challenge 21 from the 21DDC (Adapted)**\n",
    "\n",
    "Dot wants to play retro video games with all their new friends! Help them figure out which games would be best.\n",
    "\n",
    "Questions: \n",
    "    \n",
    "1. What is the top 5 best selling games released before the year 2000.\n",
    "\n",
    "     -  **Note**: Use Global_Sales\n",
    "    \n",
    "    \n",
    "2. Create a new column called Aggregate_Score, which returns the proportional average between Critic Score and User_Score based on Critic_Count and User_Count. Plot a horizontal bar chart of the top 5 highest rated games by Aggregate_Score, not published by Nintendo before the year 2000. From this bar chart, what is the highest rated game by Aggregate_Score?\n",
    "\n",
    "    -  **Note**: Critic_Count should be filled with the mean. User_Count should be filled with the median.\n",
    "    \n",
    "    \n",
    "#### In the exercise above, there is some missing values in the dataset. Look up the pandas documentation to figure out how to fill missing values in a column. You will be using the **fillna()** function in pandas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('video_games.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.fillna(value={'Critic_Count':df['Critic_Count'].mean(), 'User_Count':df['User_Count'].median()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df2['Year_of_Release'] < 2000.0\n",
    "df2[df_filter].sort_values(by = ['Global_Sales'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['User_Score'] = df3['User_Score'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Aggregate'] = (df3['Critic_Score'] * df3['Critic_Count'] + df3['User_Score'] * df3['User_Count'])/(df3['Critic_Count'] + df3['User_Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Aggregate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter = (df3['Publisher'] != 'Nintendo') & (df3['Year_of_Release'] < 2000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_plotThis = df3[df3_filter].sort_values(by = ['Aggregate'], ascending = False).iloc[0:5, [0,-1]]\n",
    "df3_plotThis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_plotThis.plot.barh(x = 'Name', y = 'Aggregate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HINT\n",
    "\n",
    "**How to create the Aggregate Score Column?**\n",
    "\n",
    "\\begin{equation*}\n",
    "AggregateScore = \\frac{(CriticCount * CriticScore)+(UserCount * UserScore)}{UserCount + CriticCount}\n",
    "\\end{equation*}\n",
    "\n",
    "**Check Your Column Values**\n",
    "\n",
    "The Critic_Score column is scored out of 100. The User_Score column is scored out of 10. You will need to modify one of the columns to match the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "In the meantime, check out pandas the user guide in the [pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html#user-guide).\n",
    "\n",
    "-------\n",
    "**Why should I use the documentation?**\n",
    "\n",
    "On the job as a data scientist or data analyst, more often than not, you may find yourself looking up the documentation of a particular function or plugin you use. Don't worry if there are a few functions you don't know by heart. However, there are just too many to know! An essential skill is to learn how to navigate documentation and understand how to apply the examples to your work. \n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional resources:\n",
    "\n",
    "- To learn more about these topics, as well as other topics not covered here (e.g. reshaping, merging, additional subsetting methods, working with text data, etc.) check out [these introductory tutorials](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) from the `pandas` documentation\n",
    "- To learn more about subsetting your data, check out [this tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#min-tut-03-subset)\n",
    "- This [pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) may also be helpful as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
