{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Part 2:\n",
    "\n",
    "**Agenda**\n",
    "\n",
    "- Sentiment Analysis\n",
    "    - Supervised learning sentiment anlaysis\n",
    "    - Sentiment as feature engineering\n",
    "    \n",
    "- Topic Modeling with LDA (Latent-Dirichlet-Allocation)\n",
    "\n",
    "\n",
    "### Quick Overview of the NLP lifecycle: From dataset to ouput\n",
    "![workflow](images/topic_workflow.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_colwidth', 0) #code to wrap text for easy viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = imdb_df = pd.read_csv(\"imdb_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace sentiment column with 1 & 0s \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "This is a dataset of movie review from the IMBD website with already labeled sentiment of positive and negative. \n",
    "\n",
    "**Target Variable is sentiment**, we will be trying to classify if it's positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK\n",
    "import nltk\n",
    "nltk.download('punkt') #download if you have not done so\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords') #download if you have not done so\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate tokenizer\n",
    "tokenizer = word_tokenize\n",
    "\n",
    "#get stop_words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['.',',',\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate vectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 2, tokenizer = tokenizer, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created our tokenizer function which will be fed into our TFIDF vectorizer down below, ideally I may want to optimize the min_df value of our vectorizer. The **min_df** used for removing terms that appear too infrequently.\n",
    "\n",
    "For example:\n",
    "* min_df = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "* min_df = 5 means \"ignore terms that appear in less than 5 documents\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB #because binary \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#build pipeline\n",
    "nlp_pipeline = Pipeline([\n",
    "    ('preprocessing', tfidf),\n",
    "    ('model', BernoulliNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.sentiment, \n",
    "                                                    test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit pipeline\n",
    "nlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = nlp_pipeline.score(X_train,y_train)\n",
    "test_accuracy = nlp_pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train accuracy:\\t{train_accuracy}')\n",
    "print(f'Test accuracy:\\t{test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test prediction\n",
    "nlp_pipeline.predict(['Hello, welcome to the happy world of data science!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we find out the sentiment of a document if it isn't labeled?\n",
    "\n",
    "There are python packages out there, such as textblob, nltk, & vaderSentiment, that makes it easy for us to determine a sentiment for any string.\n",
    "\n",
    "- You may want to do this as part of a feature engineering step.\n",
    "\n",
    "\n",
    "#### TextBlob Example\n",
    "\n",
    "Note: Make sure you install textblob, it does not come with anaconda.\n",
    "```\n",
    "pip install textblob\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ['Today is a good day!',\n",
    "            'Today is a great day!',\n",
    "            'Today is a sad day!',\n",
    "            'Today is a very bad day!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in documents:\n",
    "    print(TextBlob(i).sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polarity ranges from -1 to 1, with -1 being most negative, and 1 being most positive\n",
    "- Subjectivity is from 0 to 1, socre of 0 implying the statement is factual, score of 1 implies highly subejctive statement\n",
    "\n",
    "#### Valence Aware Dictionary and sEntiment Reasoner (VADER)\n",
    "\n",
    "- recenlty developed lexicon-based sentiment anlaysis tool, whose accuracy has been much greater than existing lexicon-based sentiment analyzers. It is better than other becauses it includes colloquial langauge terms, such as slang, emoticons, acronyms, and it also factors in the intesity of words.\n",
    "- Model deeloped by georgia tech. Read the paper on it [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf), it's an easy to read paper if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = Vader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in documents:\n",
    "    print(vader.polarity_scores(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "VADER's SentimentIntensityAnalyzer() takes in a string and returns a dictionary of scores in each of four categories:\n",
    "\n",
    "    negative\n",
    "    neutral\n",
    "    positive\n",
    "    compound (computed by normalizing the scores above)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n",
    "\n",
    "## LDA Topic Modelling\n",
    "\n",
    "**What is topic modelling? What are the use cases?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: A corpus of food magazines \n",
    "\n",
    "![exampleA](images/00_TM_food_magazines.png)\n",
    "\n",
    "### Example: A corpus of news articles\n",
    "![exampleB](images/01_TM_NYT_articles.png)\n",
    "\n",
    "\n",
    "### Topic modeling \n",
    "\n",
    "- Suppose your company has a large collection of documents on a variety of topics\n",
    "- Suppose they ask you to \n",
    "    - infer different topics in the documents\n",
    "    - pull all documents about a certain topic    \n",
    "    \n",
    "**Use Cases:**\n",
    "- Understanding customer support chat logs\n",
    "- Understanding customer reviews\n",
    "- Categorizing knowledge databases\n",
    "- Looking at the change of topics over time. \n",
    "- Any idea on combining topic modeling and sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling motivation\n",
    "\n",
    "- Humans are pretty good at reading and understanding documents and answering questions such as \n",
    "    - What is it about?  \n",
    "    - What is it related to in terms of content?     \n",
    "- Labeling by hand? \n",
    "    - Probably not\n",
    "- Use topic modeling which automates this process of inferring underlying structure in a large corpus of text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling: Input \n",
    "\n",
    "<center>\n",
    "<img src=\"images/02_TM_science_articles.png\" height=\"2000\" width=\"2000\"> \n",
    "</center>\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling: output\n",
    "<center>\n",
    "<img src=\"images/TM_topics.png\" height=\"600\" width=\"600\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling: output with interpretation\n",
    "\n",
    "- The labels are assigned manually.  \n",
    "<center>\n",
    "<img src=\"images/03_TM_topics_with_labels.png\" height=\"800\" width=\"800\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling pipeline \n",
    "\n",
    "- Feed knowlege into the machines; let it read large amount of text\n",
    "    * E.g., Wikipedia or News articles     \n",
    "- Preprocess your corpus \n",
    "    - Be careful with the features (i.e., words)\n",
    "- Train ML models\n",
    "    - For now Latent Dirichlet Allocation (LDA)\n",
    "- Interpret your topics     \n",
    "- Evaluate\n",
    "    - How well your model does on unseen documents? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baysian approach: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "- Developed by [David Blei](http://www.cs.columbia.edu/~blei/) and colleagues. \n",
    "    * One of the most cited papers in the last 15 years.\n",
    "    \n",
    "- Main Idea:\n",
    "    - Documents exhibit multiple topics\n",
    "    - A word in a document is likely to belong to the same topics the other words of that document\n",
    "    \n",
    "- Insight: \n",
    "    - Each document is a random mixture of corpus-wide topics.\n",
    "        - Every document is a discrete probability distribution of topics\n",
    "\n",
    "    - Every topic is a mixture words, aka. vocabulary, that is equal to the length of number of words in corpus.\n",
    "        - Every topic is a discrete probability distribution of words \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA: insight\n",
    "- Each document is a random mixture of corpus-wide topics\n",
    "- Every topic is a mixture words\n",
    "\n",
    "\n",
    "![lda](images/04_TM_dist_topics_words_blei.png)\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Every document is a discrete probability distribution of topics\n",
    "\n",
    "- Assume two topics: Topic 1 (topic model) and Topic 2 (fashion model)\n",
    "- Document 1: 100% topic models\n",
    "- Document 4: 100% fashion models\n",
    "- Document 7: 60% topic models + 40% fashion model\n",
    "\n",
    "<blockquote>\n",
    "Document 1: probabilistic topic model<br>\n",
    "Document 2: probabilistic topic model<br>\n",
    "Document 3: probabilistic topic model<br>\n",
    "Document 4: famous fashion model<br>\n",
    "Document 5: famous fashion model<br>\n",
    "Document 6: famous fashion model<br>\n",
    "Document 7: famous fashion model at probabilistic topic model conference<br>    \n",
    "</blockquote>\n",
    "    \n",
    "(Credit: The example is adapted from [Topic models tutorial](http://topicmodels.info/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Every topic is a discrete probability distribution of words\n",
    "\n",
    "- Assume two topics: Topic 1 (topic model) and Topic 2 (fashion model)\n",
    "- Topic 1: _model_ (0.33), _probabilistic_ (0.32), _topic_ (0.32), ...    \n",
    "- Topic 2: _model_ (0.33), _famous_ (0.32), _fashion_ (0.32), ...    \n",
    "\n",
    "<blockquote>\n",
    "Document 1: probabilistic topic model<br>\n",
    "Document 2: probabilistic topic model<br>\n",
    "Document 3: probabilistic topic model<br>\n",
    "Document 4: famous fashion model<br>\n",
    "Document 5: famous fashion model<br>\n",
    "Document 6: famous fashion model<br>\n",
    "Document 7: famous fashion model at probabilistic topic model conference<br>    \n",
    "</blockquote>\n",
    "    \n",
    "(Credit: The example is adapted from [Topic models tutorial](http://topicmodels.info/))\n",
    "\n",
    "\n",
    "![topics](images/topics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![topic_traingle](images/topics_triangle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA learning: goals\n",
    "\n",
    "Infer the underlying topic structure in the documents. In particular, \n",
    "- Learn the probability distribution of topics in each document\n",
    "- Learn the discrete probability distribution of words in each topic\n",
    "\n",
    "### LDA learning: intuition\n",
    "\n",
    "Intuition: A word in a document is likely to belong to the same topic as the other words in that document. \n",
    "\n",
    "### LDA algorithm \n",
    "\n",
    "- Choose the number of topics you think are there in your corpus\n",
    "    * Example: k = 2\n",
    "    \n",
    "### LDA algorithm\n",
    "\n",
    "- Repeat the following steps till the topics make sense:     \n",
    "- Randomly assign each words in each document to one of the topics\n",
    "    * Example: The word _probabilistic_ is randomly assigned to topic 2 (fashion).\n",
    "- Go through every word and its topic assignment in each document, looking at\n",
    "    * How often the topic occurs in the document?\n",
    "    * How often the word occurs with the topic overall? \n",
    "    * Example: Seems like topic 2 does not occur in Document 1 and the word _probabilistic_ doesn't occur much in topic 2 (fashion). So the word _probabilistic_ should probably be assigned to topic 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training LDA with [Gensim](https://radimrehurek.com/gensim/index.html)\n",
    "\n",
    "Tutorial from [here](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import smart_open\n",
    "\n",
    "def extract_documents(url='https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'):\n",
    "    with smart_open.open(url, \"rb\") as file:\n",
    "        with tarfile.open(fileobj=file) as tar:\n",
    "            for member in tar.getmembers():\n",
    "                if member.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', member.name):\n",
    "                    member_bytes = tar.extractfile(member).read()\n",
    "                    yield member_bytes.decode('utf-8', errors='replace')\n",
    "\n",
    "docs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))\n",
    "print(docs[0][:500]) #look at the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Processing\n",
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "doocs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10 #number of topics, similar to K in k-means\n",
    "chunksize = 2000 # Number of documents to be used in each training chunk.\n",
    "passes = 20 #Number of passes through the corpus during training.\n",
    "iterations = 400 #Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#import pyLDAvis.sklearn Sklearn version\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    " \n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(model, corpus, dictionary, sort_topics=False)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
