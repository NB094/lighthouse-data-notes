{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46626873-cb9b-4839-a9e2-1077bab921b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "environment = ['PYSPARK_PYTHON', 'PYSPARK_DRIVER_PYTHON']\n",
    "for var in environment:\n",
    "    os.environ[var] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb1e2ba-9c83-4b04-bdf8-63ed3e8575f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "session = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133a205f-0a0e-4083-8cbf-98d3b80891dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = session.sparkContext.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37612c42-44a7-4a78-9485-9ea5d4c53b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30211705-5a34-4dc4-91e5-f418e465a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b342fd-87c5-401a-a87d-4b204d654c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da84ab28-d19d-4533-a22b-6a909ffb1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = session.createDataFrame(\n",
    "  [[1,2,3], [4,5,6]], ['column1', 'column2', 'column3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556bad13-a716-4ef7-909a-380befd0619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|column1|column2|column3|\n",
      "+-------+-------+-------+\n",
      "|      1|      2|      3|\n",
      "|      4|      5|      6|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a table representation of the dataframe with the first n rows.\n",
    "df.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7388c977-4229-4973-8568-e0641d669d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: RDDs can't be modified in place, so you will need to code things as such:\n",
    "# my_rdd = my_rdd.map(lambda x: x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2446ab23-5d29-4c33-a4fb-29c271fc1487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------+\n",
      "|column1|column2|column3|multiplied|\n",
      "+-------+-------+-------+----------+\n",
      "|      1|      2|      3|      10.0|\n",
      "|      4|      5|      6|      40.0|\n",
      "+-------+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as funcs\n",
    "import pyspark.sql.types as types\n",
    "def multiply_by_ten(number):\n",
    "    return number*10.0\n",
    "multiply_udf = funcs.udf(multiply_by_ten, types.DoubleType())\n",
    "transformed_df = df.withColumn(\n",
    "    'multiplied', multiply_udf('column1')\n",
    ")\n",
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da9b9e6f-c42e-48ba-89a0-fe86f921cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD mapping\n",
    "\n",
    "import pyspark.sql.types as types\n",
    "import math\n",
    "def take_log_in_all_columns(row: types.Row):\n",
    "     old_row = row.asDict()\n",
    "     new_row = {f'log({column_name})': math.log(value) \n",
    "                for column_name, value in old_row.items()}\n",
    "     return types.Row(**new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f340b291-9c35-441e-bbf3-a365b9b99e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "logarithmic_dataframe = df.rdd.map(take_log_in_all_columns).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66059480-464a-44c3-a358-5079699beb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+\n",
      "|      log(column1)|      log(column2)|      log(column3)|\n",
      "+------------------+------------------+------------------+\n",
      "|               0.0|0.6931471805599453|1.0986122886681098|\n",
      "|1.3862943611198906|1.6094379124341003| 1.791759469228055|\n",
      "+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logarithmic_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc93ecb9-56db-4b27-867d-9d869614eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|column1|column2|\n",
      "+-------+-------+\n",
      "|      1|      2|\n",
      "|      4|      5|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL operations\n",
    "\n",
    "df.select('column1', 'column2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f20d5f-0892-4348-8ba5-d51d97061677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|column1|column2|column3|\n",
      "+-------+-------+-------+\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where('column1 = 3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "969f54d1-5c90-42c6-a5e6-15323baf3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.join(df1, ['column1'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae427edd-6781-4141-875e-9cf9041cc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('table1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86885a55-07ff-47bd-981b-8cf628e8dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = session.sql(\"SELECT column1 AS f1, column2 as f2 from table1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55d52680-9f24-4b72-b176-99bf8067073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|column1|column2|column3|\n",
      "+-------+-------+-------+\n",
      "|      1|      2|      3|\n",
      "|      4|      5|      6|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a6dda64-d6ed-460f-95b1-5446ddc8d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| f1| f2|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "|  4|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f67d84e8-4b4c-494b-9c39-546e1eac8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe column operations\n",
    "\n",
    "df3 = df.withColumn(\n",
    "    'derived_column', df['column1'] + df['column2'] * df['column3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e67a441-5290-49bf-91eb-0674bb14fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregations and quick statistics\n",
    "\n",
    "ADULT_COLUMN_NAMES = [\n",
    "     \"age\",\n",
    "     \"workclass\",\n",
    "     \"fnlwgt\",\n",
    "     \"education\",\n",
    "     \"education_num\",\n",
    "     \"marital_status\",\n",
    "     \"occupation\",\n",
    "     \"relationship\",\n",
    "     \"race\",\n",
    "     \"sex\",\n",
    "     \"capital_gain\",\n",
    "     \"capital_loss\",\n",
    "     \"hours_per_week\",\n",
    "     \"native_country\",\n",
    "     \"income\"\n",
    " ]\n",
    "\n",
    "csv_df = session.read.csv(\n",
    "     'adult.data.csv', header=False, inferSchema=True\n",
    " )\n",
    "for new_col, old_col in zip(ADULT_COLUMN_NAMES, csv_df.columns):\n",
    "     csv_df = csv_df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6031b761-191a-4f7a-82b5-e212925c366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|summary|               age|   workclass|            fnlwgt|    education|    education_num|marital_status|       occupation|relationship|               race|    sex|      capital_gain|    capital_loss|    hours_per_week|native_country|income|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|  count|             32561|       32561|             32561|        32561|            32561|         32561|            32561|       32561|              32561|  32561|             32561|           32561|             32561|         32561| 32561|\n",
      "|   mean| 38.58164675532078|        null|189778.36651208502|         null| 10.0806793403151|          null|             null|        null|               null|   null|1077.6488437087312| 87.303829734959|40.437455852092995|          null|  null|\n",
      "| stddev|13.640432553581356|        null|105549.97769702227|         null|2.572720332067397|          null|             null|        null|               null|   null| 7385.292084840354|402.960218649002|12.347428681731838|          null|  null|\n",
      "|    min|                17|           ?|           12285.0|         10th|              1.0|      Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|             0.0|               1.0|             ?| <=50K|\n",
      "|    max|                90| Without-pay|         1484705.0| Some-college|             16.0|       Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|          4356.0|              99.0|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31c12a30-cdcd-482f-be8d-a7fee947ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_hours_df = csv_df.groupBy(\n",
    "    'age'\n",
    ").agg(\n",
    "    funcs.avg('hours_per_week'),\n",
    "    funcs.stddev_samp('hours_per_week')\n",
    ").sort('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ef5372b-c196-4c58-be25-e964b28f58b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+---------------------------+\n",
      "|age|avg(hours_per_week)|stddev_samp(hours_per_week)|\n",
      "+---+-------------------+---------------------------+\n",
      "| 17| 21.367088607594937|         10.021014993616216|\n",
      "| 18| 25.912727272727274|         11.733362123434848|\n",
      "| 19| 30.678370786516854|         12.119154493614719|\n",
      "| 20|  32.28021248339974|         11.726599330994663|\n",
      "| 21|  34.03472222222222|         12.040389374051912|\n",
      "| 22|  35.17124183006536|         11.968466821743275|\n",
      "| 23|  36.71835803876853|         10.916632739093428|\n",
      "| 24|  39.08897243107769|         10.638975889466733|\n",
      "| 25|  40.00713436385256|         10.452953398659348|\n",
      "| 26|  41.06496815286624|          11.29552504314252|\n",
      "| 27| 42.039520958083834|         10.755941741375546|\n",
      "| 28|  42.02768166089965|         10.737113530868324|\n",
      "| 29|  42.36531365313653|         10.206157095904361|\n",
      "| 30| 42.167247386759584|         10.990266114829758|\n",
      "| 31| 42.877252252252255|         11.008740019442087|\n",
      "| 32| 42.878019323671495|          10.36006423810992|\n",
      "| 33| 42.965714285714284|         10.569643258593265|\n",
      "| 34|  42.93792325056433|         10.905945394498142|\n",
      "| 35|  43.90867579908676|         11.152690594723344|\n",
      "| 36|  43.25723830734967|         10.400753443197212|\n",
      "+---+-------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_hours_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08c98c10-d4a8-4694-92f1-4c38d9e1000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to databases\n",
    "\n",
    "session = SparkSession.builder.config(\n",
    "    'spark.jars', 'postgresql-42.2.16.jar'\n",
    ").config(\n",
    "    'spark.driver.extraClassPath', 'postgresql-42.2.16.jar'\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf44c83-1c02-40a3-94bd-46ee586e7456",
   "metadata": {},
   "source": [
    "To connect to a RDBMS you need a JDBC driver, that would be a jar file Spark can use to talk to the database. I will show you a PostgreSQL example.\n",
    "\n",
    "ref: https://jdbc.postgresql.org/download.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f20d65c-7899-4314-be5e-3d6d7f5a891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = f\"jdbc:postgresql://your_host_ip:5432/your_database\"\n",
    "# properties = {'user': 'your_user', 'password': 'your_password'}\n",
    "# # read from a table into a dataframe\n",
    "# df = session.read.jdbc(\n",
    "#     url=url, table='your_table_name', properties=properties\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca43428-0464-4f78-bb3c-2b2eb03a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df.write.jdbc(\n",
    "#     url=url, table='new_table', mode='append', properties=properties\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
