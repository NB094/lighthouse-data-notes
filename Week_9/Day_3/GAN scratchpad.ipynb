{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726dfd8d-4fcc-4de5-a93d-a08cf3e1464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm    # progress meter tool\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674084ff-4b26-4bea-9ff5-6eed73d655e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_RES = 3 # Generation resolution factor \n",
    "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = 'images/images/'\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 20\n",
    "BUFFER_SIZE = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c7f35-4e78-4bf8-ae82-414ba9ae2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images:\n",
    "\n",
    "training_binary_path = os.path.join(DATA_PATH, f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npt')\n",
    "print(f\"Looking for file: {training_binary_path}\")\n",
    "\n",
    "if not os.path.isfile(training_binary_path):\n",
    "    start = time.time9)\n",
    "    print(\"Loading training images...\")\n",
    "    \n",
    "    training data = []\n",
    "    \n",
    "    for filename in tqdm(os.listdir(DATA_PATH)):\n",
    "        path = os.path.join(DATA_PATH, filename)\n",
    "        image = Image.open(path).resizse((GENERATE_SQUARE, GENERATE_SQUARE), Image.ANTIALIAS)\n",
    "        training_data.append(np.asarray(image))\n",
    "    training_data = np.reshape(training_data, (-1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS))  #reshape: why?\n",
    "    training_data = training_data.astype(np.float32)\n",
    "    training_data = training_data / 127.5 - 1  # looks like a scaler\n",
    "    \n",
    "    print(\"Saving training image binary...\")\n",
    "    np.save(training_binary_path,training_data)   # save an array to a binary file in numpy format\n",
    "    elapsed = time.time()-start\n",
    "    print (f'Image preprocess time: {hms_string(elapsed)}')\n",
    "\n",
    "else:\n",
    "    print(\"Loading previous training pickle...\")\n",
    "    training_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4d08f-72cd-4b1e-bd47-c21d94a7ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# The tf.data.Dataset.shuffle() method randomly shuffles a tensor along its first dimension.\n",
    "# buffer_size: This is the number of elements from which the new dataset will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fae2c3-d8dc-4e4e-8108-acf586456561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()  # initialize model\n",
    "    \n",
    "    model.add(Dense(4*4*256, activation='relu', input_dim=seed_size))   # why 4*4*256? -->  image shape / (# of upsamples & strategy)\n",
    "    model.add(Reshape((4,4,256)))\n",
    "              \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))  \n",
    "    # Batch normalization applies a transformation that maintains the mean output close to 0 \n",
    "    #    and the output standard deviation close to 1.      But why do we need this?  ---> for stabilization to give better results\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Repeat layer\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding='same'))    # goes to 128 --> this number is arbitrary, but comes from a proven architecture. Typicall 2^n\n",
    "    model.add(BatchNormalization(momentum=0.8))  \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    if GENERATE_RES>1:\n",
    "        model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "        model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))  \n",
    "        model.add(Activation('relu'))\n",
    "    \n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = 3, strides=2, input_shape=image_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))  # Leaky activation layer. Why do we use leaky though? --> prevents model collapse (increases stability) \n",
    "                                                                                                # since it allows negative values to pass through\n",
    "    \n",
    "    model.add(Dropout(0.25)) # Helps prevent overfitting\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))  # Why do we need zero padding?\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Increase Conv2D nodes, decrease strides. Remove ZeroPadding.   --> strides decreases the output nodes\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))  # Why do we go to 512?  Based on proven architecture\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e105323-0f31-40ea-b79b-f6b9233553cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "# build_generator returns a \"model\" object\n",
    "\n",
    "noise = tf.random.normal([1, SEED_SIZE])  # Seed size = 100\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d56a61-9b69-44ca-bcf6-28932b5af1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is going on here? Generating a 4x7 grid of the generated images\n",
    "def save_images(cnt,noise):\n",
    "    image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), IMAGE_CHANNELS), \n",
    "      255, dtype=np.uint8)\n",
    "\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "            c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "            image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "                = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "\n",
    "\n",
    "    output_path = os.path.join(DATA_PATH,'output')\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc9612-2742-445c-9a51-f8ce5f96b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4545db-19c0-42cc-99a2-b7070fd1a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()   # Calculates loss\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaeea6f-fa69-43bf-840a-cb719db60e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ca32c-2bcd-4f31-b92e-05143ad7d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # This causes the function to be precompiled and improves performance.\n",
    "def train_step(images):\n",
    "    seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # GradientTape: \"Record operations for automatic differentiation.\"\n",
    "        generated_images = generator(seed, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(\\\n",
    "            gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(\\\n",
    "            disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        # Do these update gen_loss / disc_loss? --> yes, through apply_gradients\n",
    "        generator_optimizer.apply_gradients(zip(\n",
    "            gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(\n",
    "            gradients_of_discriminator, \n",
    "            discriminator.trainable_variables))\n",
    "        \n",
    "    return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fdef7-5210-427d-bd82-d629248a885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                   SEED_SIZE))\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        gen_loss_list = []\n",
    "        disc_loss_list = []\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            t = train_step(image_batch)\n",
    "            gen_loss_list.append(t[0])\n",
    "            disc_loss_list.append(t[1])\n",
    "\n",
    "        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "        epoch_elapsed = time.time()-epoch_start\n",
    "        print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "               f' {hms_string(epoch_elapsed)}')\n",
    "        save_images(epoch,fixed_seed)\n",
    "\n",
    "    elapsed = time.time()-start\n",
    "    print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f89ba5-43ae-4a6f-b778-186afdc92833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
